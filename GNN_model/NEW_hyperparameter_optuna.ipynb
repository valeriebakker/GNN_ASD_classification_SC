{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645463e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from args import Args\n",
    "from data_processing import load_data_and_process\n",
    "from train_and_test import train_gnn_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935f5258",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# This creates an Args() internally and returns it, along with data and phenotypic affinity\n",
    "args_base, dev_subject_IDs, test_subject_IDs, dev_features, test_features, \\\n",
    "    dev_y_true, test_y_true, pheno_affinity_matrix = load_data_and_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48521c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FOLDS = 5 \n",
    "\n",
    "def create_trial_args(base_args, trial):\n",
    "    \"\"\"\n",
    "    Copy base Args and overwrite the hyperparameters we want to tune.\n",
    "    \"\"\"\n",
    "    args = Args()\n",
    "\n",
    "    # Keep the non-tuned settings consistent with your main script\n",
    "    args.split_mode       = base_args.split_mode\n",
    "    if hasattr(base_args, \"test_percentage\"):\n",
    "        args.test_percentage = base_args.test_percentage\n",
    "    args.use_pheno_data   = base_args.use_pheno_data\n",
    "    args.model            = base_args.model\n",
    "    args.lg               = base_args.lg\n",
    "    args.patience         = base_args.patience\n",
    "    args.num_classes      = base_args.num_classes\n",
    "    args.use_batching     = base_args.use_batching\n",
    "    if hasattr(base_args, \"batch_size\"):\n",
    "        args.batch_size   = base_args.batch_size\n",
    "    if hasattr(base_args, \"num_neighbors\"):\n",
    "        args.num_neighbors = base_args.num_neighbors\n",
    "    args.activation       = base_args.activation\n",
    "    if hasattr(base_args, \"prelu_unit\"):\n",
    "        args.prelu_unit   = base_args.prelu_unit\n",
    "    args.cls_hidden       = base_args.cls_hidden\n",
    "    args.use_combat       = base_args.use_combat\n",
    "\n",
    "    args.hiddenU          = base_args.hiddenU\n",
    "\n",
    "    args.ckpt_path = None  # train_gnn_cv checks `if args.ckpt_path`\n",
    "\n",
    "    # Set the hyperparameters to optimize\n",
    "    args.dropout = trial.suggest_float(\n",
    "        \"dropout\", 0.02, 0.15\n",
    "    )\n",
    "\n",
    "    args.edge_dropout = trial.suggest_float(\n",
    "        \"edge_dropout\", 0.05, 0.25\n",
    "    )\n",
    "\n",
    "    # Log search for weight decay and learning rate\n",
    "    args.weight_decay = trial.suggest_float(\n",
    "        \"weight_decay\", 1e-5, 1e-2, log=True\n",
    "    )\n",
    "\n",
    "    args.lr = trial.suggest_float(\n",
    "        \"lr\", 5e-5, 1e-2, log=True \n",
    "    )\n",
    "\n",
    "    # Categorical number of selected SC features per subject\n",
    "    args.node_ftr_dim = trial.suggest_categorical(\n",
    "        \"node_ftr_dim\", [200, 300, 400, 500]\n",
    "    )\n",
    "\n",
    "    args.affinity_threshold = trial.suggest_float(\n",
    "        \"affinity_threshold\", 0.5, 0.7\n",
    "    )\n",
    "\n",
    "    args.epochs = 300\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934e9c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Build trial-specific args object\n",
    "    trial_args = create_trial_args(args_base, trial)\n",
    "\n",
    "    # Run k-fold CV on the development set\n",
    "    model, fold_results, mean_results, results_dir = train_gnn_cv(\n",
    "        trial_args,\n",
    "        dev_features,\n",
    "        dev_y_true,\n",
    "        pheno_affinity_matrix,\n",
    "        n_folds=N_FOLDS,\n",
    "        device=device,)\n",
    "\n",
    "    # Mean validation AUC as objective\n",
    "    val_auc_mean = mean_results[\"auc\"][0]\n",
    "\n",
    "    # Store metrics as user attributes\n",
    "    trial.set_user_attr(\"train_loss\", mean_results[\"train_loss\"][0])\n",
    "    trial.set_user_attr(\"val_loss\", mean_results[\"val_loss\"][0])\n",
    "\n",
    "    trial.set_user_attr(\"train_acc\", mean_results[\"train_accuracy\"][0])\n",
    "    trial.set_user_attr(\"val_acc\", mean_results[\"val_accuracy\"][0])\n",
    "\n",
    "    trial.set_user_attr(\"precision\", mean_results[\"precision\"][0])\n",
    "    trial.set_user_attr(\"recall\", mean_results[\"recall\"][0])\n",
    "    trial.set_user_attr(\"f1\", mean_results[\"f1_score\"][0])\n",
    "\n",
    "    trial.set_user_attr(\"specificity\", mean_results[\"specificity\"][0])\n",
    "    trial.set_user_attr(\"npv\", mean_results[\"npv\"][0])\n",
    "\n",
    "    trial.set_user_attr(\"results_dir\", results_dir)\n",
    "    trial.set_user_attr(\"fold_results\", fold_results)\n",
    "\n",
    "    trial.set_user_attr(\"results_dir\", results_dir)\n",
    "    trial.set_user_attr(\"fold_results\", fold_results)\n",
    "\n",
    "    return val_auc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43492821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_callback(study, trial):\n",
    "    print(f\"Trial {trial.number} finished.\")\n",
    "    print(f\"  Value (Val AUC): {trial.value:.4f}\")\n",
    "    # print(f\"  Value (Val acc): {trial.value:.4f}\")\n",
    "    # print(\"  Params:\")\n",
    "    # for k, v in trial.params.items():\n",
    "    #     print(f\"    {k}: {v}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"gnn_abide_val_auc\",\n",
    ")\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=200,\n",
    "    callbacks=[print_callback], \n",
    ")\n",
    "\n",
    "print(\"Best value (mean val AUC):\", study.best_value)\n",
    "print(\"Best params:\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6ed5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = study.trials_dataframe()\n",
    "df_sorted = df.sort_values(\"value\", ascending=False)\n",
    "\n",
    "# Show top 10 hyperparameter combinations ranked by val AUC\n",
    "df_top10 = df_sorted.head(10)\n",
    "df_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2488e22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6f694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.to_csv(\"C:/Users/20202932/8STAGE/Code/8STAGE_Internship/GNN_model/Results/optuna_200trials\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
